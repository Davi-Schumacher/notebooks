{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks for MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading MNIST\n",
    "Here we load the dataset and create data loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = datasets.MNIST('../data', train=True, download=True, \n",
    "                       transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))\n",
    "test_ds = datasets.MNIST('../data', train=False, download=True, \n",
    "                       transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "#batch_size = 5 # for testing\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} \n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = iter(train_loader)\n",
    "x, y = next(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper method (from fast.ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img, title=None):\n",
    "    plt.imshow(img, interpolation='none', cmap=\"gray\")\n",
    "    if title is not None: plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 1, 28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first from torch to numpy\n",
    "X = x.numpy(); Y = y.numpy()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc1612e8cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show(X[0][0], Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296]\n",
      " [-0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296]\n",
      " [-0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296]\n",
      " [-0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296]]\n"
     ]
    }
   ],
   "source": [
    "print(X[0][0][:4][:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the number of neurons in the hidden unit\n",
    "def get_model(M = 300):\n",
    "    net = nn.Sequential(nn.Linear(28*28, M),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(M, 10))\n",
    "    return net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_loader, test_loader, num_epochs, model, optimizer):\n",
    "    model.train()\n",
    "    sum_loss = 0.0\n",
    "    total = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):  \n",
    "            batch = images.shape[0] # size of the batch\n",
    "            # Convert torch tensor to Variable, change shape of the input\n",
    "            images = Variable(images.view(-1, 28*28)).cuda()\n",
    "            labels = Variable(labels).cuda()\n",
    "        \n",
    "            # Forward + Backward + Optimize\n",
    "            optimizer.zero_grad()  # zero the gradient buffer\n",
    "            outputs = model(images)\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            total += batch\n",
    "            sum_loss += batch * loss.data[0]\n",
    "            if (i+1) % 100 == 0:\n",
    "                print ('Epoch [%d/%d], Loss: %.4f' \n",
    "                   %(epoch+1, num_epochs, sum_loss/total))\n",
    "                \n",
    "        train_loss = sum_loss/total\n",
    "        print('Epoch [%d/%d], Loss: %.4f' %(epoch+1, num_epochs, train_loss))\n",
    "        val_acc, val_loss = model_accuracy_loss(model, test_loader)\n",
    "        print('Epoch [%d/%d], Valid Accuracy: %.4f, Valid Loss: %.4f' %(epoch+1, num_epochs, val_acc, val_loss))\n",
    "    return val_acc, val_loss, train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_accuracy_loss(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    sum_loss = 0.0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = Variable(images.view(-1, 28*28)).cuda()\n",
    "        labels = Variable(labels).cuda()\n",
    "        outputs = model(images)\n",
    "        _, pred = torch.max(outputs.data, 1)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        sum_loss += labels.size(0)*loss.data[0]\n",
    "        total += labels.size(0)\n",
    "        correct += pred.eq(labels.data).cpu().sum()\n",
    "    return 100 * correct / total, sum_loss/ total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.09, 2.3554891918182372)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = get_model()\n",
    "learning_rate = 0.01\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "model_accuracy_loss(net, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Loss: 0.2517\n",
      "Epoch [1/2], Loss: 0.2883\n",
      "Epoch [1/2], Loss: 0.3113\n",
      "Epoch [1/2], Loss: 0.3187\n",
      "Epoch [1/2], Loss: 0.3270\n",
      "Epoch [1/2], Loss: 0.3282\n",
      "Epoch [1/2], Loss: 0.3272\n",
      "Epoch [1/2], Loss: 0.3263\n",
      "Epoch [1/2], Loss: 0.3250\n",
      "Epoch [1/2], Loss: 0.3254\n",
      "Epoch [1/2], Valid Accuracy: 92.1800, Valid Loss: 0.2574\n",
      "Epoch [2/2], Loss: 0.3254\n",
      "Epoch [2/2], Loss: 0.3264\n",
      "Epoch [2/2], Loss: 0.3261\n",
      "Epoch [2/2], Loss: 0.3268\n",
      "Epoch [2/2], Loss: 0.3269\n",
      "Epoch [2/2], Loss: 0.3273\n",
      "Epoch [2/2], Loss: 0.3272\n",
      "Epoch [2/2], Loss: 0.3271\n",
      "Epoch [2/2], Loss: 0.3268\n",
      "Epoch [2/2], Loss: 0.3274\n",
      "Epoch [2/2], Valid Accuracy: 87.9600, Valid Loss: 0.3971\n"
     ]
    }
   ],
   "source": [
    "train_model(train_loader, test_loader, num_epochs=2, model=net, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models with L2 regularization\n",
    "To add L2 regularization use the `weight_decay` argument on the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models with Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_v2(M = 300, p=0):\n",
    "    modules = []\n",
    "    modules.append(nn.Linear(28*28, 10))\n",
    "    modules.append(nn.ReLU())\n",
    "    if p > 0:\n",
    "        modules.append(nn.Dropout(p))\n",
    "    modules.append(nn.Linear(M, 10))\n",
    "    return nn.Sequential(*modules).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = get_model_v2(M = 300, p=0.1)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/4], Loss: 0.1764\n",
      "Epoch [1/4], Loss: 0.1793\n",
      "Epoch [1/4], Loss: 0.1763\n",
      "Epoch [1/4], Loss: 0.1796\n",
      "Epoch [1/4], Loss: 0.1755\n",
      "Epoch [1/4], Loss: 0.1760\n",
      "Epoch [1/4], Loss: 0.1745\n",
      "Epoch [1/4], Loss: 0.1738\n",
      "Epoch [1/4], Loss: 0.1751\n",
      "Epoch [1/4], Loss: 0.1763\n",
      "Epoch [1/4], Valid Accuracy: 94.9800, Valid Loss: 0.2079\n",
      "Epoch [2/4], Loss: 0.1748\n",
      "Epoch [2/4], Loss: 0.1736\n",
      "Epoch [2/4], Loss: 0.1731\n",
      "Epoch [2/4], Loss: 0.1730\n",
      "Epoch [2/4], Loss: 0.1740\n",
      "Epoch [2/4], Loss: 0.1724\n",
      "Epoch [2/4], Loss: 0.1719\n",
      "Epoch [2/4], Loss: 0.1718\n",
      "Epoch [2/4], Loss: 0.1718\n",
      "Epoch [2/4], Loss: 0.1719\n",
      "Epoch [2/4], Valid Accuracy: 94.7000, Valid Loss: 0.2242\n",
      "Epoch [3/4], Loss: 0.1717\n",
      "Epoch [3/4], Loss: 0.1719\n",
      "Epoch [3/4], Loss: 0.1712\n",
      "Epoch [3/4], Loss: 0.1706\n",
      "Epoch [3/4], Loss: 0.1698\n",
      "Epoch [3/4], Loss: 0.1702\n",
      "Epoch [3/4], Loss: 0.1699\n",
      "Epoch [3/4], Loss: 0.1697\n",
      "Epoch [3/4], Loss: 0.1693\n",
      "Epoch [3/4], Loss: 0.1689\n",
      "Epoch [3/4], Valid Accuracy: 95.0600, Valid Loss: 0.2296\n",
      "Epoch [4/4], Loss: 0.1696\n",
      "Epoch [4/4], Loss: 0.1687\n",
      "Epoch [4/4], Loss: 0.1683\n",
      "Epoch [4/4], Loss: 0.1678\n",
      "Epoch [4/4], Loss: 0.1671\n",
      "Epoch [4/4], Loss: 0.1672\n",
      "Epoch [4/4], Loss: 0.1671\n",
      "Epoch [4/4], Loss: 0.1674\n",
      "Epoch [4/4], Loss: 0.1665\n",
      "Epoch [4/4], Loss: 0.1664\n",
      "Epoch [4/4], Valid Accuracy: 94.6400, Valid Loss: 0.2339\n"
     ]
    }
   ],
   "source": [
    "train_model(train_loader, test_loader, num_epochs=4, model=net, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
